<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Camera Access Example</title>
  </head>
  <body>
    <h1>Camera Access Example</h1>
    <!-- Update the video, canvas, and button elements in HTML -->
    <video id="videoElement" width="400" height="300" autoplay></video>
    <canvas id="canvas" width="400" height="300" style="display: none"></canvas>
    <button id="segmentationButton">Start Segmentation</button>
    <span id="flag_1_345"></span>
    <span id="flag_8_910"></span>
    <script>
      document.addEventListener("DOMContentLoaded", () => {
        const videoElement = document.getElementById("videoElement");
        const canvas = document.getElementById("canvas");
        const context = canvas.getContext("2d");
        const segmentationButton =
          document.getElementById("segmentationButton");
        const resultImageElement = document.createElement("img");
        let isSegmentationActive = false;
        let socket;

        // Function to toggle segmentation start/stop
        function toggleSegmentation() {
          isSegmentationActive = !isSegmentationActive;

          if (isSegmentationActive) {
            // Start segmentation
            segmentationButton.innerText = "Stop Segmentation";
            socket = new WebSocket(
              "ws://" + window.location.host + "/ws/segmentation/"
            );

            socket.onopen = (event) => {
              console.log("WebSocket connection opened:", event);
            };

            socket.onmessage = (event) => {
              // Receive segmentation result from the backend
              const result = JSON.parse(event.data);
              // Update the canvas with the segmentation result
              document.getElementById("flag_1_345").innerText =
                result.flag_1_345;
              document.getElementById("flag_8_910").innerText =
                result.flag_8_910;

              resultImageElement.src = `data:image/png;base64,${result.result_frame}`;
              document.body.appendChild(resultImageElement);
            };
          } else {
            // Stop segmentation
            segmentationButton.innerText = "Start Segmentation";
            if (socket) {
              socket.close();
            }
          }
        }

        segmentationButton.addEventListener("click", toggleSegmentation);

        navigator.mediaDevices
          .getUserMedia({ video: true })
          .then((stream) => {
            videoElement.srcObject = stream;
          })
          .catch((error) => {
            console.error("Error accessing camera:", error);
          });

        setInterval(() => {
          if (isSegmentationActive) {
            // Capture a frame from the video stream
            context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

            // Convert the frame to base64 data
            const imageData = canvas.toDataURL("image/jpeg");

            // Send the frame to the backend (Django) through WebSocket
            socket.send(JSON.stringify({ frame: imageData }));
          }
        }, 400); // Adjust the interval as needed
      });
    </script>
  </body>
</html>
